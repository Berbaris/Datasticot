{"cells":[{"cell_type":"markdown","source":["# Functions\n","\n","This notebook contains reusable functions used in other notebooks. It should be run at the beginning of each notebook using ```%%run NB_Functions```.\n","\n","Contains the following functions:\n","- get_dir_content\n","- extract_date_from_path\n","- get_most_recent_date_in_epoch\n","- get_most_recent_date\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8a643611-6ce7-433d-8045-18354f319833"},{"cell_type":"code","source":["import re\n","from notebookutils import mssparkutils\n","from datetime import datetime"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"61cb1926-a7e7-490f-9af4-570e54a9d516"},{"cell_type":"code","source":["def get_dir_content(folder_path, extension=None):\n","    \"\"\"\n","    Recursively retrieves all files within a root folder. Optionally filters files by their extension.\n","\n","    Arguments:\n","    folder_path : str : Path to the root folder to search.\n","    extension : str : Optional. File extension to filter by (e.g., '.json').\n","\n","    Returns:\n","    List of file paths.\n","    \"\"\"\n","    dir_paths = mssparkutils.fs.ls(folder_path)\n","    all_paths = []\n","\n","    for p in dir_paths:\n","        if p.isDir:\n","            all_paths.extend(get_dir_content(p.path, extension))\n","        else:\n","            if extension is None or p.path.endswith(extension):\n","                all_paths.append(p.path)\n","    \n","    return all_paths\n","\n","def extract_date_from_path(file_path):\n","    \"\"\"\n","    Extracts the date from a file path using regular expressions. Date needs to match the YYYY/MM/DD structure.\n","\n","    Arguments:\n","    file_path: path to the file to extract the date from.\n","\n","    Returns:\n","    Date in format YYYY/MM/DD if found in the file path, None otherwise.\n","    \"\"\"\n","    match = re.search(r'/(\\d{4}/\\d{2}/\\d{2})/', file_path)     # Regular expression to match date in the path in format YYYY/MM/DD\n","\n","    if match:\n","        date_str = match.group(1)\n","        date_obj = datetime.strptime(date_str, '%Y/%m/%d')\n","        return date_obj\n","\n","    return None\n","\n","def get_most_recent_date_in_epoch(files):\n","    \"\"\"\n","    Extracts dates from a list of files and returns the most recent date in epoch format. Dates are extracted using the extract_date_from_path function.\n","\n","    Arguments:\n","    files: list of files to extract the date from.\n","\n","    Returns:\n","    Date in epoch format.\n","    \"\"\"\n","    file_dates = [extract_date_from_path(file) for file in files]     # Extract dates from files\n","    most_recent_date = max(file_dates)    # Get the most recent file\n","\n","    return int(most_recent_date.timestamp())\n","\n","def get_most_recent_date(files):\n","    \"\"\"\n","    Extracts dates from a list of files and returns the most recent date in YYYY/MM/DD format. Dates are extracted using the extract_date_from_path function.\n","\n","    Arguments:\n","    files: list of files to extract the date from.\n","\n","    Returns:\n","    Date in YYYY/MM/DD format.\n","    \"\"\"\n","    file_dates = [extract_date_from_path(file) for file in files]     # Extract dates from files\n","    most_recent_date = max(file_dates)    # Get the most recent file\n","\n","    return most_recent_date\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8ce8f4b7-8473-41d4-b405-7a03330d25cd"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"spark_compute":{"compute_id":"/trident/default"}},"nbformat":4,"nbformat_minor":5}
