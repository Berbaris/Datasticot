{"cells":[{"cell_type":"markdown","source":["# Ingest Historical Summoner Games API to Bronze\n","This notebook loads the historical summoner games (up to April the 16th 2024) data from the League of Legends API. Cf. detail on the API by Riot Games on: https://developer.riotgames.com/\n","\n","It requires the list of summoners for which we want to get data as input.\n","\n","The list of summoners from which you want to get data was loaded in a csv file created for that and manually ingested in the Files section of the Bronze Lakehouse. The csv file contains summoner name (which can change) ,the Player Universally Unique ID (puuid, which cannot change) and the Summoner ID (which is needed for some API calls). The puuid was fetched using the summoner API : https://euw1.api.riotgames.com/lol/summoner/v4/summoners/by-name/\"summoner-name\"\n","\n","_Note: historical games are not actually used as for most old games, the games detail API does not work._\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5d271939-2371-461e-9b64-73ea70f7a7b9"},{"cell_type":"markdown","source":["### 1. General configuration"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4260ee3a-f2f1-46b6-bde1-c8ec416438cb"},{"cell_type":"code","source":["# Import libraries\n","from trident_token_library_wrapper import PyTridentTokenLibrary as tl\n","import requests as r\n","import json\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType\n","from pyspark.sql import Row\n","from datetime import datetime\n","import time"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bb915a2c-4c29-41f0-8838-a8e2b736ffac"},{"cell_type":"code","source":["# Load secrets from Azure Key Vault\n","key_vault_name = 'testasa-akv-dev-001'\n","key_name = 'lol-api-key'\n","access_token = mssparkutils.credentials.getToken(\"keyvault\")\n","api_key = tl.get_secret_with_token(f\"https://{key_vault_name}.vault.azure.net/\", key_name, access_token)\n","\n","# Define API endpoint and parameters\n","base_url = 'https://europe.api.riotgames.com/lol/'\n","batch_size = 100"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"feaf5ca8-b780-4c9c-8e3b-58695e7e1ab4"},{"cell_type":"markdown","source":["### 2. Load historical Summoner Games data"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"1a66aa4a-76c4-4f14-9631-35b8bfc320a3"},{"cell_type":"code","source":["# Read Summoners.csv into a DataFrame\n","print(\"Reading summoners csv file into a DataFrame\")\n","df_summoners = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\", \";\").csv(\"Files/raw_data/Summoners.csv\")\n","print(\"Finished reading summoners csv file into a DataFrame, found\", df_summoners.count(), \"summoners\")\n","\n","# Make a list out of the PUUIDs to iterate on PUUIDs\n","puuid_list = df_summoners.select('PUUID').collect()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6d246dfb-91de-4b4b-988c-b6d237f335b0"},{"cell_type":"code","source":["# Make API calls to get games of each summoner and collect responses\n","print(\"Starting API calls to get summoner games\")\n","\n","all_games = []\n","current_date = datetime.now().strftime(\"%Y-%m-%d\")\n","\n","for puuid_row in puuid_list:\n","    print(f\"Getting data for puuid: {puuid_row[0]} \")\n","    offset = 0\n","    puuid = puuid_row[0]\n","    \n","    while True:\n","        # Make API call to fetch game identifiers for the current batch\n","        print(f\"Getting data from games {offset} to {offset + batch_size}\")\n","        params = {'api_key': api_key, 'count': batch_size, 'start': offset}\n","        response = r.get(f\"{base_url}match/v5/matches/by-puuid/{puuid}/ids\", params=params)\n","        \n","        if response.status_code == 200:\n","            # Append retrieved game identifiers to the list\n","            games = response.json()\n","            for game in games:\n","                all_games.append({\"puuid\": puuid, \"game\": game, \"date\": current_date})\n","        else:\n","            print(f\"Failed to fetch game identifiers for summoner {puuid}\")\n","            break\n","        \n","        # Check if there are more batches to fetch\n","        if not games:\n","            break\n","        else:\n","            offset += batch_size\n","            \n","    time.sleep(30) # see API limits: https://developer.riotgames.com/docs/portal"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d7805b0c-0b5d-4b75-937e-cd1425f31a0b"},{"cell_type":"code","source":["# Define the schema for the Summoner Games\n","schema = StructType([\n","    StructField(\"puuid\", StringType(), True),\n","    StructField(\"game\", StringType(), True),\n","    StructField(\"date\", StringType(), True)\n","])\n","\n","# Create DataFrame from the collected rows and schema\n","df_summoner_games = spark.createDataFrame(all_games, schema=schema)\n","\n","# Save file to appropriate bronze folder; replace old file if it already existed\n","print(f\"Writing summoner games data to Bronze Lakehouse Files\")\n","df_summoner_games.coalesce(1).write.mode(\"overwrite\").json('Files/raw_data/summoner_games/historical')"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"72430684-18ff-4e09-9044-3470bef2c0a6"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"language_group":"synapse_pyspark"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"286263bd-7967-44b3-91d7-009c5f2d484d","known_lakehouses":[{"id":"286263bd-7967-44b3-91d7-009c5f2d484d"}],"default_lakehouse_name":"LKH_Bronze","default_lakehouse_workspace_id":"f7e91c17-bfad-4e28-ae2d-fe11a87d13d7"}}},"nbformat":4,"nbformat_minor":5}